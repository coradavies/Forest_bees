---
title: "Forest Bees Code"
author: "Cora Davies"
date: "2/28/2022"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)

library(tidyverse)
library(ggplot2)
library(ggpubr)
library(cowplot)
library(grid)
library(gridExtra)
library(gtable)
library(emmeans)
library(dunn.test)
library(ncf)
library(VennDiagram)
library(hrbrthemes)
library(tm)
library(proustr)
library(vegan)
library(iNEXT)
library(bipartite)
library(ape) 
library(caper)
library(nlme) 
library(lavaan) 
library(lme4)
library(DiagrammeR)
library(semPlot)
library(piecewiseSEM)
library(corrplot)
library(RColorBrewer)
library(mvabund)
library(lattice)
library(ade4)
library(dbplyr)

```

### DATA ANALYSIS    

This R markdown document contains the analyses conducted for "Forest restoration treatments enhance plant-pollinator networks via floral- and temperature-mediated resource cascades."

```{r}

# Import data
  #Forest structure
Basal_area <- read.csv("Basal_Area.csv")
Tree_density <- read.csv("Tree_Density.csv")
Sky <- read.csv("CanopyOpenness.csv")

  #Nesting habitat
Ground_Cover <- read.csv("Ground_Cover.csv")
CWD <- read.csv("CWD.csv")

  #Temperature data
T1_Temp <- read.csv("T1_Temp.csv")
T2_Temp <- read.csv("T2_Temp.csv")
T3_Temp <- read.csv("T3_Temp.csv")
T4_Temp <- read.csv("T4_Temp.csv")
T5_Temp <- read.csv("T5_Temp.csv")
T6_Temp <- read.csv("T6_Temp.csv")
T7_Temp <- read.csv("T7_Temp.csv")
T8_Temp <- read.csv("T8_Temp.csv")
T9_Temp <- read.csv("T9_Temp.csv")
T10_Temp <- read.csv("T10_Temp.csv")
T11_Temp <- read.csv("T11_Temp.csv")
T12_Temp <- read.csv("T12_Temp.csv")
T13_Temp <- read.csv("T13_Temp.csv")
T14_Temp <- read.csv("T14_Temp.csv")
T15_Temp <- read.csv("T15_Temp.csv")
C16_Temp <- read.csv("C16_Temp.csv")
C17_Temp <- read.csv("C17_Temp.csv")
C18_Temp <- read.csv("C18_Temp.csv")
C19_Temp <- read.csv("C19_Temp.csv")
C20_Temp <- read.csv("C20_Temp.csv")
C21_Temp <- read.csv("C21_Temp.csv")
C22_Temp <- read.csv("C22_Temp.csv")
C23_Temp <- read.csv("C23_Temp.csv")
C24_Temp <- read.csv("C24_Temp.csv")
C25_Temp <- read.csv("C25_Temp.csv")
C26_Temp <- read.csv("C26_Temp.csv")
C27_Temp <- read.csv("C27_Temp.csv")
C28_Temp <- read.csv("C28_Temp.csv")
C29_Temp <- read.csv("C29_Temp.csv")
C30_Temp <- read.csv("C30_Temp.csv")

  #Foraging habitat
Floral_Quadrats<- read.csv("Floral_Quadrats.csv", header=TRUE) 

  #Bee species analyses
BeeID<- read.csv("BeeIdentification.csv", header=TRUE) 
SiteInfo<- read.csv("SiteInformation.csv", header=TRUE) 
traits<- read.csv("GenusTraits.csv", header=TRUE, row.names=1)

SEMvars <- read.csv("SEMvars.csv")

```

## Forest Structure
This section of the R Markdown document is for the analyses examining the effects of forest thinning on forest structure including:  
    -	Mean basal area  
    -	Mean tree density
    -	Average quadratic mean diameter  
    -	Canopy cover

# Mean basal area

Calculate the average basal area at each site (n=10/site) and convert data from ft^2 / acre to m^2 / hectare. _(1 square foot / acre = 0.229568411 square meters / hectare)_  

```{r}
#Calculate averages and save as new data frame
BAmeans<- group_by(Basal_area, Treatment, Site) %>% summarize(ba = mean(BA.live))

#Convert data to correct units
BAmeans<-BAmeans %>% add_column(BA_converted = (BAmeans$ba*0.229568411))

```

Analyze data using 2-sample t-test.

```{r}
#test equal variance
var.test(BA_converted ~ Treatment, data=BAmeans)
#test normality
shapiro.test(BAmeans$BA_converted)
hist(BAmeans$BA_converted)
#var not equal use Welch 
t.test(BA_converted ~ Treatment, data=BAmeans,
       conf.level=0.95)
#Calculate SE
BAsd<- BAmeans %>% group_by(Treatment) %>% summarize(sd = sd(BA_converted))
BAsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualization: Create a box plot of the data. 

```{r}

#Plot data
BAplot<- ggplot(BAmeans, aes(x = Treatment, y = BA_converted, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Basal~area~(m^2/ha)))+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=42)

```

# Mean tree density

Calculate the number of trees per hectare based on the number of trees with in the 0.1ha plots. 

```{r}

#Calculate number of trees per hectare
library(tidyverse)
Tree_density<-Tree_density %>% add_column(Trees_ha = (Tree_density$Total_Trees*10))

```

Analyze data using 2-sample t-test.

```{r}

#test equal variance
var.test(Trees_ha ~ Treatment, data=Tree_density)
#test normality
shapiro.test(Tree_density$Trees_ha)
hist(Tree_density$Trees_ha)
#var not equal use Welch 
t.test(Trees_ha ~ Treatment, data=Tree_density,
       conf.level=0.95)

#Calculate SE
Treesd<- Tree_density %>% group_by(Treatment) %>% summarize(sd = sd(Trees_ha))
Treesd$sd/sqrt(15) #1=control; 2=thinned

```

Visualization: create a box plot of the data. 

```{r}

#Plot data
Treedensityplot<- ggplot(Tree_density, aes(x = Treatment, y = Trees_ha, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Tree~density~(trees/ha)))+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=750)

```

# Average quadratic mean diameter

{\displaystyle {\sqrt {\frac {BA}{k*n}}}}

where BA is stand basal area, n is the number of trees, and k is a constant based on measurement units (for BA in m2 and DBH in cm, k=0.0000785).

```{r}
#Calculate the QMD using the tree density and basal area
  #add BA to tree density data
  Tree_density<-Tree_density %>% add_column(BA = (BAmeans$BA_converted))

  #calculate average QMD
  QMD<-sqrt((abs(Tree_density$BA))/(Tree_density$Trees_ha*0.0000785))

  #add QMD in new column
  Tree_density<-Tree_density %>% add_column(QMD =QMD)
```

Analyze data using 2-sample t-test.

```{r}
#test equal variance
var.test(QMD ~ Treatment, data=Tree_density)
#test normality
shapiro.test(Tree_density$QMD)
hist(Tree_density$QMD)

#variance equal
t.test(QMD ~ Treatment, data=Tree_density, var.equal = TRUE, conf.level=0.95)
#Calculate SE
QMDsd<- Tree_density %>% group_by(Treatment) %>% summarize(sd = sd(QMD))
QMDsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}

#Plot data
QMDplot<- ggplot(Tree_density, aes(x = Treatment, y = QMD, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("QMD (cm)")+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=42, hide.ns=TRUE) +
  coord_cartesian(ylim = quantile(Tree_density$QMD, c(0, .97)))

```

# Canopy cover

Calculate mean canopy openness per sites (Using data from GLA). 

```{r}

#Calculate mean canopy openness per sites
meanSky<-  Sky %>% group_by(Treatment, Site) %>% summarize(Sky = mean(Sky))

```

Compare the data of thinned sites to non-thinned.

```{r}

#test equal variance
var.test(Sky ~ Treatment, data=meanSky)
#test normality
shapiro.test(meanSky$Sky)
hist(meanSky$Sky)
#variance not equal equal
t.test(Sky ~ Treatment, data=meanSky, var.equal = TRUE, conf.level=0.95)

#Calculate SE
Skysd<- meanSky %>% group_by(Treatment) %>% summarize(sd = sd(Sky))
Skysd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data and graphic of all forest structure variables

```{r}

#Plot sky data
Skyplot<- ggplot(meanSky, aes(x = Treatment, y = Sky, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Canopy openness (%)")+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=100)

#Graphic for all forest structure variables
plot_grid(BAplot + theme(legend.position="none"), Treedensityplot + theme(legend.position="none"), Skyplot, align = "h", ncol = 3, rel_widths= c(1, 1, 1.5), labels="AUTO")

```

## Nesting habitat

# Ground Cover

Edit the data to count the abundance of each type.

```{r}

GC<- Ground_Cover %>% group_by(Site, Treatment, Cover_type) %>% summarize(frequency = n())

GC <- GC %>%
  spread(key = Cover_type, value = frequency)

#change NA cells to 0
GC<- GC %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))

#Save data
write.csv(GC, "GroundCover.csv")

```

We can run a t-test on any of the cover types to directly compare them...

```{r}
#check variance
var.test(Bare ~ Treatment, data=GC)
#Run Students 2-sample t-test
t.test(Bare ~ Treatment, data=GC,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
Baresd<- GC %>% group_by(Treatment) %>% summarize(sd = sd(Bare))
Baresd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}

treatmentlabs<-(c("Control","Thinned"))

#Plot data
Bareplot<- ggplot(GC, aes(x = Treatment, y = Bare, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment)) + 
  ylab("Bare ground (% cover)")+
  labs(x= "Treatment Type") +
  scale_fill_grey(start = .5, end = .9, name="Treatment",
                         breaks=c("C", "T"),
                         labels=c("Control", "Thinned"))+ 
  scale_x_discrete(labels= treatmentlabs)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)

```

# Fuel Loads

To analyze fuel loads the equation from Van Wagner (1968) was used. The next step is to calculate the volume for each site. 

```{r}

#reorder to match other data
CWD<- CWD %>% relocate(Site)

#Convert diameter from inches to cm
CWD<- CWD %>% mutate(Diameter = Diameter*2.54)

#create new column (d^2/800)- 800 is 8 times length (=100)
CWD<- CWD %>%
  mutate(Diameter2= ((Diameter^2)/800))

#add row for T9 since volume was zero
CWD <-CWD %>% add_row(Treatment = "Thinned", Site = "T9", Transect=1, Log_Number=1, Diameter=0, Decay="NA", Diameter2=0)

#create new data with summary of each site 
CWD_V<- CWD %>% group_by(Site, Treatment) %>% summarize(Volume = (pi^2 *(sum(Diameter2))))

#save data
write.csv(CWD_V, "CWD_V.csv")

```

Run t-test to compare between sites: 

```{r}
#check variance
var.test(Volume ~ Treatment, data=CWD_V)
#Run Students 2-sample t-test
t.test(Volume ~ Treatment, data=CWD_V,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
CWDsd<- CWD_V %>% group_by(Treatment) %>% summarize(sd = sd(Volume))
CWDsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}

treatmentlabs<-(c("Control","Thinned"))

#Plot data
CWDplot<- ggplot(CWD_V, aes(x = Treatment, y = Volume, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment)) + 
  ylab(expression(Volume~(m^3/ha)))+
  labs(x= "Treatment Type") +
  scale_fill_grey(start = .5, end = .9, name="Treatment",
                         breaks=c("C", "T"),
                         labels=c("Control", "Thinned"))+ 
  scale_x_discrete(labels= treatmentlabs)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

```

## Temperature

Combine all temperature data and summarize (mean, max, min).

```{r}

#calculate mean site temp

TempSummary <- data.frame(Site =c("T1","T2","T3","T4","T5","T6","T7","T8","T9","T10","T11","T12","T13","T14","T15","C16","C17","C18","C19","C20","C21","C22","C23","C24","C25","C26","C27","C28","C29","C30"),
                            Treatment=c("Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned","Thinned", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control"),
                          MeanTemp = c(mean(T1_Temp$Temp),mean(T2_Temp$Temp),mean(T3_Temp$Temp),mean(T4_Temp$Temp),mean(T5_Temp$Temp),mean(T6_Temp$Temp),mean(T7_Temp$Temp),mean(T8_Temp$Temp),mean(T9_Temp$Temp),mean(T10_Temp$Temp),mean(T11_Temp$Temp),mean(T12_Temp$Temp),mean(T13_Temp$Temp),mean(T14_Temp$Temp),mean(T15_Temp$Temp),mean(C16_Temp$Temp),mean(C17_Temp$Temp),mean(C18_Temp$Temp),mean(C19_Temp$Temp),mean(C20_Temp$Temp),mean(C21_Temp$Temp),mean(C22_Temp$Temp),mean(C23_Temp$Temp),mean(C24_Temp$Temp),mean(C25_Temp$Temp),mean(C26_Temp$Temp),mean(C27_Temp$Temp),mean(C28_Temp$Temp),mean(C29_Temp$Temp),mean(C30_Temp$Temp)),
                           MaxTemp = c(max(T1_Temp$Temp),max(T2_Temp$Temp),max(T3_Temp$Temp),max(T4_Temp$Temp),max(T5_Temp$Temp),max(T6_Temp$Temp),max(T7_Temp$Temp),max(T8_Temp$Temp),max(T9_Temp$Temp),max(T10_Temp$Temp),max(T11_Temp$Temp),max(T12_Temp$Temp),max(T13_Temp$Temp),max(T14_Temp$Temp),max(T15_Temp$Temp),max(C16_Temp$Temp),max(C17_Temp$Temp),max(C18_Temp$Temp),max(C19_Temp$Temp),max(C20_Temp$Temp),max(C21_Temp$Temp),max(C22_Temp$Temp),max(C23_Temp$Temp),max(C24_Temp$Temp),max(C25_Temp$Temp),max(C26_Temp$Temp),max(C27_Temp$Temp),max(C28_Temp$Temp),max(C29_Temp$Temp),max(C30_Temp$Temp)),
                            MinTemp = c(min(T1_Temp$Temp),min(T2_Temp$Temp),min(T3_Temp$Temp),min(T4_Temp$Temp),min(T5_Temp$Temp),min(T6_Temp$Temp),min(T7_Temp$Temp),min(T8_Temp$Temp),min(T9_Temp$Temp),min(T10_Temp$Temp),min(T11_Temp$Temp),min(T12_Temp$Temp),min(T13_Temp$Temp),min(T14_Temp$Temp),min(T15_Temp$Temp),min(C16_Temp$Temp),min(C17_Temp$Temp),min(C18_Temp$Temp),min(C19_Temp$Temp),min(C20_Temp$Temp),min(C21_Temp$Temp),min(C22_Temp$Temp),min(C23_Temp$Temp),min(C24_Temp$Temp),min(C25_Temp$Temp),min(C26_Temp$Temp),min(C27_Temp$Temp),min(C28_Temp$Temp),min(C29_Temp$Temp),min(C30_Temp$Temp))
                 )

#save data
write.csv(TempSummary, "TempSummary.csv")


#check variance
var.test(MaxTemp ~ Treatment, data=TempSummary)
#Run Students 2-sample t-test
#max
t.test(MaxTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
maxsd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MaxTemp))
maxsd$sd/sqrt(15) #1=control; 2=thinned

#mean
t.test(MeanTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
meansd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MeanTemp))
meansd$sd/sqrt(15) #1=control; 2=thinned

#min
t.test(MinTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
minsd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MinTemp))
minsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create box plot.

```{r}
#Create figure

MeanTemp<- ggplot(TempSummary, aes(x=Treatment, y=MeanTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Mean Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=20)

MaxTemp<- ggplot(TempSummary, aes(x=Treatment, y=MaxTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Maximum Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=40)

MinTemp<- ggplot(TempSummary, aes(x=Treatment, y=MinTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Minimum Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))


SupplementalS2 <- ggarrange(MeanTemp, MaxTemp, MinTemp,
                    labels = c("A", "B", "C"),
                    ncol = 3, nrow = 1, common.legend=TRUE,legend="top")

```

## Foraging Habitat
The next section of this R Markdown document is for the analyses examining the effects of forest thinning on bee foraging resources. 

# Mean foral abundance

Mean floral abundance calculated using the number of flowers in each m^2 quadrat. Calculated the average number of flowers/m^2 in each site at each sampling time (month)

```{r}

#create new data frame with the average floral abundance at each site by month 

Floralab<- group_by(Floral_Quadrats, Treatment, Site, Month) %>% summarize(floralab = mean(Count))

Floralabpooled<-group_by(Floral_Quadrats, Site, Treatment) %>% summarize(floralab = sum(Count))

```

Create ANOVA model. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-wild test residuals are NOT normally distributed  **Consider transforming data**

```{r}

#Create the linear model 
lmflowerab <- lm(floralab ~ Treatment * Month, data=Floralab) 

#check normality 
par(mfrow=c(2,2))
plot(lmflowerab)

#run anova
anova(lmflowerab)
emout <- emmeans(lmflowerab, ~ Treatment*Month)
pairs(emout)

```

Plot data.

```{r}
#order by month
Floralab$Month <- factor(Floralab$Month,levels = c("June", "July", "August"))

#create box plots 
Floralabplot<- ggplot(Floralab, aes(x=Month, y=floralab, fill=Treatment)) + 
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Floral~density~(count/m^2)))+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=10)+ coord_cartesian(ylim = quantile(Floralab$floralab, c(0, 0.99)))

FloralabSum <- Floralab %>%
  group_by(Month, Treatment) %>%
  summarise(n = n(),
            mean = mean(floralab))

#pooled across months
FloralabSumStats <- Floralab %>%
  group_by(Site,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralab))

Floralabpooledplot<- ggplot(FloralabSumStats, aes(x=Treatment, y=mean, fill=Treatment)) + 
 geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Floral~density~(count/m^2)))+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)


#test equal variance
var.test(mean ~ Treatment, data=FloralabSumStats)
#variance not equal equal
t.test(mean ~ Treatment, data=FloralabSumStats, var.equal = TRUE, conf.level=0.95)
#Calculate SE
floralsd<- FloralabSumStats %>% group_by(Treatment) %>% summarize(sd = sd(mean))
floralsd$sd/sqrt(15) #1=control; 2=thinned

```

# Number of floral species

First we must calculate the floral species richness.  

```{r, warning=FALSE}
#create new data frame with the floral species richness at each site by month 

#Remove all rows with "None" listed as species
Floralrich <- Floral_Quadrats %>% 
  filter(!grepl('None', Species))

#Calculate floral richness
Floralrich <- Floralrich %>% group_by(Treatment,Site,Month) %>% 
  summarize(floralrich = length(unique(Species))) #counts unique values of species names
Floralrichpooled <- Floral_Quadrats %>% filter(!grepl('None', Species))%>% group_by(Site, Treatment) %>% 
  summarize(floralrich = length(unique(Species))) #counts unique values of species names
#add missing row
c17<-data.frame("C17","Control",0)
  #Naming the Data Frame
names(c17) <- c("Site", "Treatment", "floralrich")  
  #Using rbind() function to insert above observation  
Floralrichpooled <- rbind(Floralrichpooled, c17)  
#save as csv
write.csv(Floralrichpooled, "Floralrichpooled.csv")


#add missing rows to df
  #create missing rows
df4<- data.frame (c("Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control"),
                  c("C16","C16","C17","C17","C17","C18","C18","C19","C20","C22","C23","C24","C25","C26","C26","C29","C30","C30"),
                  c("July","August","June","July","August","July","August","August","August","August","August","August","August","July","August","August","July","August"),
                  c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))
  #Naming the Data Frame
names(df4) <- c("Treatment", "Site", "Month", "floralrich")  
  #Using rbind() function to insert above observation  
Floralrich <- rbind(Floralrich, df4)  

```

Next, create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-wild test residuals are NOT normally distributed  **Consider transforming data**

```{r}
#create linear model
lmfloralrich <- lm(floralrich ~ Treatment * Month, data=Floralrich) 

#visually inspect to evaluate assumptions
par(mfrow=c(2,2))
plot(lmfloralrich)

#run anova
anova(lmfloralrich)
emout <- emmeans(lmfloralrich, ~ Treatment*Month)
pairs(emout)

#non-parametric test Kruskal-Wallis
kruskal.test(formula=floralrich~Treatment,data=Floralrich)
dunn.test(x=Floralrich$floralrich,g=Floralrich$Treatment)
dunn.test(x=Floralrich$floralrich,g=Floralrich$Month)

```

Plot data.

```{r}
#order by month
Floralrich$Month <- factor(Floralrich$Month,levels = c("June", "July", "August"))

#create box plots 
Floralrichplot<- ggplot(Floralrich, aes(x=Month, y=floralrich, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Floral species richness \n (# species)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=8)+ coord_cartesian(ylim = quantile(Floralrich$floralrich, c(0.1, 0.99))) 

Floralrich1 <- Floralrich %>%
  group_by(Month,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralrich))

#pooled across month
FloralrichSumStats <- Floralrich %>%
  group_by(Site,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralrich))

Floralrichpooledplot<- ggplot(FloralrichSumStats, aes(x=Treatment, y=mean, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Floral species richness \n (# species)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)

#test equal variance
var.test(mean ~ Treatment, data=FloralrichSumStats)
#variance not equal equal
t.test(mean ~ Treatment, data=FloralrichSumStats, var.equal = TRUE, conf.level=0.95)
#Calculate SE
floralrichsd<- FloralrichSumStats %>% group_by(Treatment) %>% summarize(sd = sd(mean))
floralrichsd$sd/sqrt(15) #1=control; 2=thinned

```
SAVE ALL DATA CREATED IN CSV FOR FUTURE ANALYSES

```{r}

##FOREST STRUCTURE
#create new dataframe with all forest structure variables
ForestStructure<- Tree_density %>% add_column(Sky = meanSky$Sky, .after = "QMD")
#save data
write.csv(ForestStructure, "ForestStructure.csv")

##FORAGAING HABITAT

#create list of data frames to combine
data_list2 <- list(Floralab, Floralrich)     
#merge data
ForagaingHabitat<-data_list2 %>% reduce(inner_join, by = c("Site","Month","Treatment"))  
#save data
write.csv(ForagaingHabitat, "ForagingHabitat.csv")


data_list3 <- list(Floralabpooled, Floralrichpooled)     
#merge data
ForagaingHabitatpooled<-data_list3 %>% reduce(inner_join, by = c("Site", "Treatment"))  
#save data
write.csv(ForagaingHabitatpooled, "ForagingHabitatpooled.csv")

```

CREATE FIGURE WITH ALL ITEMS

```{r}

Fig3 <- ggarrange(BAplot, Treedensityplot, QMDplot, Skyplot, Floralabpooledplot, Floralrichpooledplot, Bareplot, CWDplot,
                    labels = "AUTO",
                    ncol = 4, nrow = 2, common.legend=TRUE,legend="top") 


SupplementalS4 <- ggarrange(Floralabplot, Floralrichplot,
                    labels = c("A", "B"),
                    ncol = 1, nrow = 2, common.legend=TRUE,legend="top")

```


## Bee species analyses

    1) Two-factor ANOVA (Month and Treatment)
          A) Bee abundance
          B) Bee species richness
          C) Shannon-weiner diversity index (H')
    2) Sample curves (iNEXT package)
          A) Bee species β-diversity 
    3) Effects of site status on community composition
          A) Bray-Curtis dissimilarities (Species-abundance matrix)
          B) Non-metric multidimensional scaling (NMDS) (‘metaMDS’ function in vegan)  
          

# ncf 

```{r}

#remove unidentified bee species
BeeID2<-subset(BeeID, GenusSpecies!="Unknown")

#Create abundance matrix by site 
Beeabmatrix <- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
Beeabmatrix <- Beeabmatrix %>%
  spread(key = GenusSpecies, value = abundance)
Beeabmatrix<- Beeabmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
Beeabmatrix<- Beeabmatrix %>% 
  column_to_rownames("Site")

#ncf
SiteInfo<- SiteInfo %>% arrange(SITE)
  
x<- SiteInfo$LONGITUDE
y<- SiteInfo$LATITUDE
z<- Beeabmatrix

ncf<- spline.correlog(x=x, y=y, z=z, latlon=T, resamp=1000)
S1<- plot(ncf)

```

# 1A Bee abundances

**Comparison by month**  

First, calculate the bee abundance across sites and months. 
```{r, warning=FALSE}

#Calculate bee abundance at each site at each month
Beeabmonth<- BeeID %>% group_by(Site, Treatment, Month) %>% summarize(beeab = length(unique(Number)))
#add missing rows to df
  #create missing rows
df1<- data.frame (c("C17", "C26", "C29"), 
                  c("Control","Control","Control"),
                  c("August","August","August"),
                  c(0,0,0))
  #Naming the Data Frame
names(df1) <- c("Site", "Treatment", "Month", "beeab")  
  #Using rbind() function to insert above observation  
Beeabmonth <- rbind(Beeabmonth, df1) 

Beeabpooled <- BeeID %>% group_by(Site, Treatment) %>% summarize(beeab = length(unique(Number)))

```

Create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-wild test residuals are NOT normally distributed  **Consider transforming data**

```{r}
#create linear
lmbeeabmonth <- lm(beeab ~ Treatment * Month, data=Beeabmonth) 

#run anova
anova(lmbeeabmonth)
emout <- emmeans(lmbeeabmonth, ~ Treatment*Month)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeeabmonth)

```


Plot data.

```{r}
#order by month
Beeabmonth$Month <- factor(Beeabmonth$Month,levels = c("June", "July", "August"))

#create box plots 
fig5A<- ggplot(Beeabmonth, aes(x=Month, y=beeab, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee abundance")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=42)

BeeabSum <- Beeabmonth %>%
  group_by(Month,Treatment) %>%
  summarise(n = n(),
            mean = mean(beeab))
            
BeeabSum

```


**Comparison by capture method** 

First, calculate the bee abundance across sites and capture method. 
```{r, warning=FALSE}

#Calculate bee abundance at each site at each month
Beeabmethod<- BeeID %>% group_by(Site, Treatment, Method) %>% summarize(beeab = length(unique(Number)))

#add missing rows to df
  #create missing rows
df2<- data.frame (c("C17", "C22", "C23","C24","C26","C30"), 
                  c("Control","Control","Control","Control","Control","Control"),
                  c("Net","Net","Net","Net","Net","Net"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df2) <- c("Site", "Treatment", "Method", "beeab")  
  #Using rbind() function to insert above observation  
Beeabmethod <- rbind(Beeabmethod, df2) 

```

Create linear model and run ANOVA. Check assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-wild test residuals are NOT normally distributed  **Consider transforming data**

```{r}
#create linear model to run tests on assumptions
lmbeeabmethod <- lm(beeab ~ Method, data=Beeabmethod) 

#run anova
anova(lmbeeabmethod)
emout <- emmeans(lmbeeabmethod, ~ Method)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeeabmethod)

```

Plot data.

```{r}

#create box plots 
S6<- ggplot(Beeabmethod, aes(x=Method, y=beeab, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee abundance")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=38, hide.ns=TRUE)

```

Venn diagram

```{r}
#create summary data
Beerichmethod <- BeeID2 %>% group_by(Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#create diagram (S7)

venn.diagram(x = list(
    Beerichmethod %>% filter(Method=="Blue vane") %>% select(GenusSpecies) %>% unlist(), 
    Beerichmethod %>% filter(Method=="Net") %>% select(GenusSpecies) %>% unlist(),
    Beerichmethod %>% filter(Method=="Pan trap") %>% select(GenusSpecies) %>% unlist()),
  category.names = c("Blue vane" , "Net" , "Pan trap"),
   filename = 'S7_venndiagram.png',
  output=TRUE)

```

NMDS to compare bee species composition between capture methods. 

```{r}

#create matrix (rows=site, columns= bee species frequency counts)
abmatrix<- BeeID2 %>% group_by(Site, Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
abmatrix <- abmatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
abmatrix<- abmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#remove method column
abmatrix<-as.data.frame(abmatrix)
abmatrix <- abmatrix %>% select(-Method)
#make first column row names
abmatrix$Site <- row.names(abmatrix$Site)

#create metadata
metamatrix<- BeeID2 %>% group_by(Site, Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
metamatrix <- metamatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
metamatrix<- metamatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
metamatrix<- metamatrix %>% select(c(Site,Method))

#create dissimilarity matrix
dist.matrix = as.matrix(vegdist(abmatrix, "bray"))

adonis2(abmatrix~Method, data=metamatrix, permutations=9999, method="bray")
```

## 1B Bee species richness

Calculate bee species richness from bee ID data by site and month. 
```{r}
#create new data frame with the bee species richness at each site by month 

#Calculate bee species richness
Beerich <- BeeID2 %>% group_by(Treatment,Site,Month) %>% 
  summarize(beerich = length(unique(GenusSpecies))) #counts unique values of species names
#add missing rows to df
  #create missing rows
df3<- data.frame (c("Control","Control","Control"),
                  c("C17", "C26", "C29"), 
                  c("August","August","August"),
                  c(0,0,0))
  #Naming the Data Frame
names(df3) <- c("Treatment", "Site", "Month", "beerich")  
  #Using rbind() function to insert above observation  
Beerich <- rbind(Beerich, df3)  

#save data created
write.csv(Beerich,'BeeSpeciesRichness.csv')

### Bee richness pooled for GLM
Beerich2 <- BeeID2 %>% group_by(Site, Treatment) %>% 
  summarize(beerich = length(unique(GenusSpecies)))
#save data created
write.csv(Beerich2,'BeeSpeciesRichnesspooled.csv')

```

Plot the species richness data:  
```{r}

#order by month
Beerich$Month <- factor(Beerich$Month,levels = c("June", "July", "August"))

#plot data using ggplot
fig5B<- ggplot(Beerich, aes(x=Month, y=beerich, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  labs(y="Bee richness")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=19, hide.ns=TRUE)

```

Create linear model and run ANOVA. 

```{r}

#create linear model 
lmbeerich <- lm(beerich ~ Treatment * Month, data=Beerich) 

#run anova
anova(lmbeerich)
emout <- emmeans(lmbeerich, ~ Treatment*Month)
pairs(emout)

```

## 1C Species diversity  

Create species abundance matrix
```{r}
#Calculate bee abundance at each site at each month

Beespecies<- BeeID2 %>% group_by(SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

BeeSAM <- Beespecies %>%
  spread(key = GenusSpecies, value = abundance)

#change NA cells to 0
matrix<- BeeSAM %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))

#Edit data so that there are only site-month as row names
matrix<- column_to_rownames(matrix, "SiteMonth") #make fist column the row names
head(matrix) #check data

#save data created
write.csv(matrix,'BeeSAM.csv')
```

The following is used to calculate the species diversity at each sampling time. 

```{r}

#create species diversity dataframe (use same format as construction of species abundance matrix)
Beediversity<- BeeID2 %>% group_by(SiteMonth, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance)

#Edit data so that there are only site-month 
Beediversity<- select(Beediversity, 1, 2) 

#Calculate and add diversity to the existing ‘Beediversity’ data frame
Beediversity$Shannon=diversity(matrix, index="shannon")
Beediversity$Simpson=diversity(matrix, index="simpson")
head(Beediversity) #check data 

#add site and month columns
Beediversity<-separate(data=Beediversity, col=SiteMonth, into=c("Month","Site",sep="-"))
Beediversity<- select(Beediversity, -3) 

#Save bee diversity data as csv
write.csv(Beediversity,'BeeDiversity.csv')

#create pooled diversity by site for GLM
Beediversitypooled<- BeeID2 %>% group_by(Site, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance) %>% select(1, 2) 

#Calculate bee abundance at each site
matrixpooled<- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance) %>%
  mutate_all(funs(ifelse(is.na(.), 0, .))) #change NA cells to 0

#Edit data so that there are only site-month as row names
matrixpooled<- column_to_rownames(matrixpooled, "Site") #make fist column the row names
head(matrixpooled) #check data

#Calculate and add diversity to the existing ‘Beediversity’ data frame
Beediversitypooled$Shannon=diversity(matrixpooled, index="shannon")
Beediversitypooled$Simpson=diversity(matrixpooled, index="simpson")
head(Beediversitypooled) #check data 

#Save bee diversity data as csv
write.csv(Beediversitypooled,'BeeDiversitypooled.csv')

```

Plot the species diversity data:  

```{r}
#plot data using ggplot

Beediversity$Month <- factor(Beediversity$Month,levels = c("June", "July", "August"))

fig5C<- ggplot(Beediversity, aes(x=Month, y=Shannon, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  labs(y="Bee diversity")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=2.6, hide.ns=TRUE)

```


Create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are equal by Levene's test and data is approximately normally distributed. Residuals v fitted also shows approximately equal variances. Normal Q-Q is heavily skewed. Shapiro-wild test residuals are NOT normally distributed. Assumptions mostly met. 

```{r}
#create linear model 
lmbeediversity <- lm(Shannon ~ Treatment * Month, data=Beediversity) 

#run anova
anova(lmbeediversity)
emout <- emmeans(lmbeediversity, ~ Treatment*Month)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeediversity)

Beediversity %>% group_by(Treatment) %>%
  summarize(Shannon=mean(Shannon))

```

Save compiled bee data for future analyses. 

```{r}

#create list of data frames to combine
data_list <- list(Beeabpooled, Beerich2)

#merge data
BeeStats<-data_list %>% reduce(inner_join, by = c("Site", "Treatment"))  

#save data
write.csv(BeeStats, "BeeStats.csv")

#create figure of combined figures

figure5_1 <- ggarrange(fig5A, fig5B, fig5C,
                    labels = c("A","B","C"),
                    ncol = 3, nrow = 1, common.legend=TRUE,legend="right")

```

## 2A Sample curves for Bee species β-diversity 
Format data correctly to create species accumulation curves:

```{r}

## LIST FOR CONTROL 
beecurveC<- BeeID2 %>% group_by(Treatment, SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#remove thinned
beecurveC = filter(beecurveC, Treatment != "Thinned")

#make species columns (first column as treatment)
beecurveC <- beecurveC %>%
  spread(key = SiteMonth, value = abundance)
#remove thinned
beecurveC = filter(beecurveC, Treatment != "Thinned")

#add missing values
beecurveC$AugustC17 <- NA 
beecurveC$AugustC26 <- NA  
beecurveC$AugustC29 <- NA  

#change NA cells to 0
beecurveC<- beecurveC %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#change all values greater than 1 to 1
beecurveC[3:47] <- lapply(beecurveC[3:47], function(x) ifelse( x>1, 1, x))

#remove column 1
beecurveC<- beecurveC[,-1]

#calculate row-sums (this will become the incidence frequencies)
beecurveClist<-select(beecurveC, - GenusSpecies) %>% {rowSums(.)}
#add total number sampling units
beecurveClist<-c(45,beecurveClist)
#make list
beecurveClist<-list(beecurveClist)

##LIST FOR THINNED
beecurveT<- BeeID2 %>% group_by(Treatment, SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#remove control
beecurveT = filter(beecurveT, Treatment != "Control")

#make species columns (first column as treatment)
beecurveT <- beecurveT %>%
  spread(key = SiteMonth, value = abundance)

#change NA cells to 0
beecurveT<- beecurveT %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#change all values greater than 1 to 1
beecurveT[3:47] <- lapply(beecurveT[3:47], function(x) ifelse( x>1, 1, x))

#remove column 1
beecurveT<- beecurveT[,-1]

#calculate row-sums (this will become the incidence frequencies)
beecurveTlist<-select(beecurveT, - GenusSpecies) %>% {rowSums(.)}
#add total number sampling units
beecurveTlist<-c(45,beecurveTlist)
#make list
beecurveTlist<-list(beecurveTlist)

#add names to lists
beecurvelist <- setNames((c(beecurveClist, beecurveTlist)), c("Control", "Thinned"))

```

Analyzing and graphing the curves

```{r}

#create the curve using iNEXT
t <- seq(1, 90, by=10)
out <- iNEXT(beecurvelist, q=c(0, 1, 2), datatype="incidence_freq", size=t)

# Sample‐size‐based R/E curves
figure5_2<- ggiNEXT(out, type=1, facet.var="order", color.var="site", grey=TRUE)+
    theme_classic(base_size = 12) + 
  theme(legend.position="right")

figure5 <- ggarrange(figure5_1, figure5_2, 
                    labels = c("", "D"),
                    ncol = 1, nrow = 2)

```
    
## 3A Bray-Curtis dissimilarities (Species-abundance matrix)

Using the species-abundance matrix ("matrix") created earlier, transform into Bray-Curtis dissimilarities. Analyze the effects of site status on community composition using the ‘adonis2’ function (permutational multivariate analysis of variance, n permutations = 9999) in the R add-on package ‘vegan’ V2.5-522.
```{r}

#create matrix (rows=site, columns= bee species frequency counts)
abmatrix<- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
abmatrix <- abmatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
abmatrix<- abmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#make first column row names
abmatrix <- abmatrix %>% column_to_rownames(var="Site")


#create metadata
metamatrix<- BeeID2 %>% group_by(Site, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
metamatrix <- metamatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
metamatrix<- metamatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
metamatrix<- metamatrix %>% select(c(Site,Treatment))


#create dissimilarity matrix
dist.matrix = as.matrix(vegdist(abmatrix, "bray"))

adonis2(abmatrix~Treatment, data=metamatrix, permutations=9999, method="bray")
```          

## 3B Non-metric multidimensional scaling (NMDS)

Create visual of the results using non-metric multidimensional scaling (NMDS), produced with the ‘metaMDS’ function in package ‘vegan’.  

First we have to create the NMDS model and extract the site and species scores.

```{r}
#create NMDS value
NMDSmodel<- metaMDS(abmatrix, k=2)
treat=c(rep("Control",15),rep("Thinned",15))
ordiplot(NMDSmodel,type="n")
ordihull(NMDSmodel,groups=treat,draw="polygon",col="grey90",label=F)
orditorp(NMDSmodel,display="sites",col=c(rep("purple",15),rep("blue",15)), air=0.01,cex=1.25)

#build a data frame with NMDS coordinates and metadata
MDS1 = NMDSmodel$points[,1]
MDS2 = NMDSmodel$points[,2]
NMDS = data.frame(NMDS1 = MDS1, NMDS2 = MDS2, Treatment = treat)

#Plot data
Thinned <- NMDS[NMDS$Treatment == "Thinned", ][chull(NMDS[NMDS$Treatment == 
    "Thinned", c("NMDS1", "NMDS2")]), ]  # hull values for thinned
Control <- NMDS[NMDS$Treatment == "Control", ][chull(NMDS[NMDS$Treatment == 
    "Control", c("NMDS1", "NMDS2")]), ]  # hull values for control

hull.data <- rbind(Thinned, Control)  #combine thinned and control

#stress to annotate plot
NMDSmodel$stress

S5<- ggplot() + 
   geom_polygon(data=hull.data,aes(x=NMDS1,y=NMDS2,fill=Treatment,group=Treatment),alpha=0.30) + # add the convex hulls
  geom_point(data=NMDS,aes(x=NMDS1,y=NMDS2,shape=Treatment, fill=Treatment),size=4) + # add the point markers
  scale_fill_grey(start = .3, end = .7)+
  coord_equal() +
  theme_classic() 

```

## Bipartite analysis 


The following section is to analyze the plant-pollinator (flower-bee) network. Specifically, the goal is to	analyze number of linkages and interactions. To perform this analysis I will use the "bipartite" package (https://cran.r-project.org/web/packages/bipartite/vignettes/Intro2bipartite.pdf).

```{r}
#data with only netting
BeesNet<- filter(BeeID, Method == "Net")

FloralInteractions<- BeesNet %>% group_by(Treatment, Flower, GenusSpecies) %>% summarize(Count = length(unique(Number)))

#Remove not recorded values
FloralInteractions<-FloralInteractions[!(FloralInteractions$Flower=="Not recorded"),]
FloralInteractions<-FloralInteractions[!(FloralInteractions$GenusSpecies=="Unknown"),]

#Remove Wood and Ground entries 
FloralInteractions<-FloralInteractions[!(FloralInteractions$Flower=="Ground"|FloralInteractions$Flower=="Wood"),]

FloralInteractions<- as.data.frame(FloralInteractions) #convert to df

#total number of interactions (NOT unique; unique interactions calculated below)
FloralInteractions %>% 
  group_by(Treatment) %>% 
  summarise(interactions= sum(Count))

```


Once data is correctly formatted, then you can make the interaction matrix: 

```{r}
#create web (i.e., interaction matrix)
Web<-frame2webs(FloralInteractions, varnames=c("Flower","GenusSpecies","Treatment", "Count"), type.out="list") #create matrix
#calculate 
sapply(frame2webs(FloralInteractions,varnames=c("Flower","GenusSpecies","Treatment", "Count"),type.out="list"), networklevel, index=c("connectance", "C score"))
```

Visualize the data:

```{r}
### BY FAMILY

##Format data
FloralInteractions2<- BeesNet %>% group_by(Treatment, Flower, GenusSpecies, Family) %>% summarize(Count = length(unique(Number)))

#Remove not recorded values
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$Flower=="Not recorded"),]
#Remove Wood and Ground entries 
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$Flower=="Ground"|FloralInteractions2$Flower=="Wood"),]
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$GenusSpecies=="Unknown"),]

#add family-genusspecies column
FloralInteractions2$FamilySpecies<-paste(FloralInteractions2$Family,FloralInteractions2$GenusSpecies,sep=" - ")

FloralInteractions2<- as.data.frame(FloralInteractions2) #convert to df

#Create web with each species with species; colored by family

Web2<-frame2webs(FloralInteractions2, varnames=c("FamilySpecies","Flower","Treatment", "Count"), type.out="list") #create matrix

#visualization
par(font = 3) #italics
data(Web2)
#Control 
plotweb(Web2$Control, col.low=c("#0072B2","#0072B2","#0072B2",
                               "#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7",
                               "#F0E442","#F0E442","#F0E442","#F0E442","#F0E442",
                    "#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73", "#009E73","#009E73"),
        text.rot=90, method="normal", y.lim=c(-1.5,3))

#Thinned
par(font = 3) #italics
data(Web2)

plotweb(Web2$Thinned,method="normal", col.low=c("#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2",
                               "#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7",
                               "#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00",
                               "#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442",
                    "#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73"), 
	text.rot=90, y.lim=c(-1.5,3))

```


#Analyse the data
Network metrics:
-	Network-level specialization (H2′) (networklevel function)
-	Modularity (computemodules function, with method set to “Beckett)
-	Weighted nestedness (WNODF) (networklevel function)

```{r}
#Network-level specialization and WNODF
networklevel(Web$Control, index="H2")
networklevel(Web$Thinned, index="H2")

#Weighted nestedness (WNODF)
networklevel(Web$Control, index="weighted NODF")
networklevel(Web$Thinned, index="weighted NODF")
Cdegree<- specieslevel(Web$Control, index= "degree", level="higher")
sum(Cdegree$degree)

Tdegree<- specieslevel(Web$Thinned, index= "degree", level="higher")
sum(Tdegree$degree)
#Modularity
modC<-computeModules(Web$Control, method="Beckett") 
plotModuleWeb(modC, weighted=TRUE) #S10A
modC@likelihood

modT<-computeModules(Web$Thinned, method="Beckett") 
plotModuleWeb(modT, weighted=TRUE) #S10B
modT@likelihood

```
#Comparing metrics to a null model 

***NETWORK LEVEL SPECIALIZATION*** 

```{r}

#Control
Iobs <- networklevel(Web$Control, index="H2")

nulls <- nullmodel(web=Web$Control, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="H2")

plot(density(Inulls), xlim=c(0, 1), lwd=2, main="H2'")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
1-pnorm(z)


#Thinned
Iobs <- networklevel(Web$Thinned, index="H2")

nulls <- nullmodel(web=Web$Thinned, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="H2")

plot(density(Inulls), xlim=c(0, 1), lwd=2, main="H2'")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
1-pnorm(z)


## Comparing differences (is difference between H2 significant?)

# Write a function to compute the desired statistic, e.g. the difference
# between thinned and control:
meandiff <- function(webs){
  obs <- sapply(webs, networklevel, index="H2")
  mean(obs[1] - obs[2])}


(observed <- meandiff(Web))

## Creating a null model: 

nulllist <- lapply(Web, nullmodel, N=1, method="r2d")

#Repeat this procedure 1000 times
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
nulllist <- sapply(Web, nullmodel, N=1, method="r2d")
res[i] <- meandiff(nulllist)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-0.4, 0.4), border="white", col="grey")
abline(v=observed, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < observed)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((observed-mean(res))/sd(res))
pnorm(z)
```

***WEIGHTED NESTEDNESS***

```{r}

#Control
Iobs <- networklevel(Web$Control, index="weighted NODF")

nulls <- nullmodel(web=Web$Control, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="weighted NODF")

plot(density(Inulls), xlim=c(-1, 5), lwd=2, main="WNODF'")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
pnorm(z)


#Thinned
Iobs <- networklevel(Web$Thinned, index="weighted NODF")

nulls <- nullmodel(web=Web$Thinned, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="weighted NODF")

plot(density(Inulls), xlim=c(5, 20), lwd=2, main="WNODF")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
pnorm(z)

# Write a function to compute the desired statistic, e.g. the difference
# between thinned and control:
meandiff <- function(webs){
  obs <- sapply(webs, networklevel, index="weighted NODF")
  mean(obs[1] - obs[2])}


(observed <- meandiff(Web))

## Creating a null model: 

nulllist <- lapply(Web, nullmodel, N=1, method="r2d")

meandiff(Web)

#Repeat this procedure 1000 times
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
nulllist <- sapply(Web, nullmodel, N=1, method="r2d")
res[i] <- meandiff(nulllist)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-14, -2), border="white", col="grey")
abline(v=observed, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < observed)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((observed-mean(res))/sd(res))
1-pnorm(z)

```
***MODULARITY***
Dormann & Strauss, 2013

https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12139

https://besjournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2F2041-210X.12139&file=mee312139-sup-0001-AppendixS1.pdf

```{r}
#Create web not separated by treatment
Web_mod<-frame2webs(FloralInteractions, varnames=c("Flower","GenusSpecies", "Count"), type.out="list") #create matrix

#Create null models (THIS WILL TAKE A COUPLE HOURS)
nulls <- nullmodel(Web_mod$'1', N=100, method="r2d")
modules.nulls <- sapply(nulls, computeModules)
like.nulls <- sapply(modules.nulls, function(x) x@likelihood)

#Calculate z scores comparing observed to nulls 
(z <- (modC@likelihood - mean(like.nulls))/sd(like.nulls))
1-pnorm(z)
(z <- (modT@likelihood - mean(like.nulls))/sd(like.nulls))
1-pnorm(z)

#Observed difference
obsdif<- modC@likelihood-modT@likelihood

#create lists of differences in Q (modularity) of null models
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
res[i] <- sample(like.nulls,1, replace=FALSE)-sample(like.nulls,1, replace=FALSE)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-.2, .2), border="white", col="grey")
abline(v=obsdif, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < obsdif)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((obsdif-mean(res))/sd(res))
1-pnorm(z)


#Using modularity to identifying species with important roles in the network

null.cz <- lapply(modules.nulls, czvalues)
# compute 95
null.cs <- sapply(null.cz, function(x) x$c) # c-values across all species in nulls
quantile(null.cs, 0.95) 
null.zs <- sapply(null.cz, function(x) x$z) # c-values across all species in nulls
quantile(null.zs, na.rm=TRUE, 0.95) 
# this can now serve as thresholds for identifying particularly uncommonly high c-values

#Control
  #lower
cz <- czvalues(modC, level="lower")
plot(cz[[1]], cz[[2]], pch=16, xlab="c", ylab="z", cex=0.8, xlim=c(0,1), ylim=c(-1,3), las=1)
abline(v=0.72)
abline(h=1.788854)
  #higher
cz <- czvalues(modC, level="higher")
plot(cz[[1]], cz[[2]], pch=16, xlab="c", ylab="z", cex=0.8, xlim=c(0,1), ylim=c(-1,3), las=1)
abline(v=0.72)
abline(h=1.788854) 

#Thinned
  #lower
cz <- czvalues(modT, level="lower")
plot(cz[[1]], cz[[2]], pch=16, xlab="c", ylab="z", cex=0.8, xlim=c(0,1), ylim=c(-1,3), las=1)
abline(v=0.72)
abline(h=1.788854)
  #higher
cz <- czvalues(modT, level="higher")
plot(cz[[1]], cz[[2]], pch=16, xlab="c", ylab="z", cex=0.8, xlim=c(0,1), ylim=c(-1,3), las=1)
abline(v=0.72)
abline(h=1.788854)

```

# Structural Equation Model

This section is used to construct and analyze a structural equation model (SEM). The SEMs were fit using the r package piecewiseSEM following Lefcheck (2016). Model evaluation = Shipley (2009).

Open-source example: https://github.com/jslefche/piecewiseSEM


Format data and normalize values: 

```{r}
#normalize values
#calculate means and sd
means<- SEMvars %>% group_by() %>% 
  summarise_at(vars(Trees_ha:Elevation), mean)

sd<- SEMvars %>% group_by() %>% 
  summarise(across(Trees_ha:Elevation ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
SEMvars_norm <- transform(SEMvars, 
                          Trees_ha=(Trees_ha-means$Trees_ha)/sd$Trees_ha,
                          BA=(BA-means$BA)/sd$BA,
                          QMD=(QMD-means$QMD)/sd$QMD,
                          Sky=(Sky-means$Sky)/sd$Sky,
                          floralab=(floralab-means$floralab)/sd$floralab,
                   floralrich=(floralrich-means$floralrich)/sd$floralrich,
                          beeab = (beeab-means$beeab)/sd$beeab,
                          beerich = (beerich-means$beerich)/sd$beerich,
                          Shannon = (Shannon-means$Shannon)/sd$Shannon,
                          Simpson = (Simpson-means$Simpson)/sd$Simpson,
                          Bare=(Bare-means$Bare)/sd$Bare, 
                          Forb=(Forb-means$Forb)/sd$Forb,
                          Grass=(Grass-means$Grass)/sd$Grass, 
                          Litter=(Litter-means$Litter)/sd$Litter, 
                          Rock=(Rock-means$Rock)/sd$Rock,
                          Shrub=(Shrub-means$Shrub)/sd$Shrub, 
                          Tree=(Tree-means$Tree)/sd$Tree,
                          Wood=(Wood-means$Wood)/sd$Wood,
                          Volume=(Volume-means$Volume)/sd$Volume,
                          MeanTemp=(MeanTemp-means$MeanTemp)/sd$MeanTemp,
                          MaxTemp=(MaxTemp-means$MaxTemp)/sd$MaxTemp,
                          MinTemp=(MinTemp-means$MinTemp)/sd$MinTemp,
                   interactionab=(interactionab-means$interactionab)/sd$interactionab,
                   interactionrich=(interactionrich-means$interactionrich)/sd$interactionrich,
                   HLI=(HLI-means$HLI)/sd$HLI,
                   Elevation=(Elevation-means$Elevation)/sd$Elevation)

write.csv(SEMvars_norm, "SEMvarsnorm.csv")

#remove unknown
BeeID2<-subset(BeeID, GenusSpecies!="Unknown")


#data with only netting
BeesNet<- filter(BeeID2, Method == "Net")

#abundance
Netbeeab<- BeesNet %>% group_by(Site) %>% summarize(beeab2 = length(unique(Number)))
#add missing rows to df
  #create missing rows
df2<- data.frame (c("C17", "C22", "C23","C24","C26","C30"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df2) <- c("Site", "beeab2")  
  #Using rbind() function to insert above observation  
Netbeeab <- rbind(Netbeeab, df2) 

#normalize values
#calculate means and sd
means2<- Netbeeab %>% group_by() %>% 
  summarise_at(vars(beeab2), mean)

sd2<- Netbeeab %>% group_by() %>% 
  summarise(across(beeab2 ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
Netbeeab_norm <- transform(Netbeeab, 
                          beeab2 = (beeab2-means2$beeab2)/sd2$beeab2)

Netbeeab_norm <- as.data.frame(Netbeeab_norm)

##RICHNESS##
Netbeerich<- BeesNet %>% group_by(Site) %>% summarize(beerich2 = length(unique(GenusSpecies)))
  #create missing rows
df3<- data.frame (c("C17", "C22", "C23","C24","C26","C30"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df3) <- c("Site", "beerich2")  
  #Using rbind() function to insert above observation  
Netbeerich <- rbind(Netbeerich, df3)

#normalize values
#calculate means and sd
means3<- Netbeerich %>% group_by() %>% 
  summarise_at(vars(beerich2), mean)

sd3<- Netbeerich %>% group_by() %>% 
  summarise(across(beerich2 ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
Netbeerich_norm <- transform(Netbeerich, 
                          beerich2 = (beerich2-means3$beerich2)/sd3$beerich2)

Netbeerich_norm <- as.data.frame(Netbeerich_norm)
                          

```

Create SEM, using data from net captures only.

```{r}

# Add net only data to vars df
#merge data
vars <- SEMvars_norm
vars2<- inner_join (vars, Netbeeab_norm, by = "Site") 
vars2<- inner_join (vars2, Netbeerich_norm, by = "Site")


bee_pSEM2 <- psem(
  #LMM models
  lme(beeab2 ~ Bare + MaxTemp + floralab + floralrich, random = ~ 1 | Site, data = vars2),
  lme(beerich2 ~ Bare + MaxTemp + floralab + floralrich, random = ~ 1 | Site, data = vars2),
  lme(floralab ~ Sky + Bare, random = ~ 1 | Site, data = vars2),
  lme(floralrich ~ Sky + Bare, random = ~ 1 | Site, data = vars2),
  lme(interactionab ~ floralrich + floralab + beerich2 + beeab2, random = ~ 1 | Site, data = vars2),
  lme(interactionrich ~ floralrich + floralab + beerich2 + beeab2, random = ~ 1 | Site, data = vars2),
  lme(MaxTemp ~ Sky, random = ~1 | Site, data = vars2),
     #correlated errors
  floralab %~~% floralrich,
  beeab2 %~~% beerich2,
  interactionab %~~% interactionrich)
 
(new.summary2 <- summary(bee_pSEM2, .progressBar = F))

dSep(bee_pSEM2)

coefficents2 <- new.summary2$coefficients

write.csv(coefficents2, "SEMcoef_Net.csv")

```


## Linear regressions (Figure 4)

Linear regressions to compare floral habitat to forest structure (BA)

```{r}

#floral abundance vs  BA
fig4A<- ggscatter(SEMvars,x="BA",y="floralab",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=35, label.y=300, r.accuracy = 0.001)+
  stat_regline_equation(label.x=35, label.y=250)+
  ylab("Floral abundance")+
  xlab("Basal area")+
  ylim(-75,300)+
  theme(legend.title = element_blank())

ggscatter(
  SEMvars, x = "BA", y = "floralab",
  color = "Treatment", palette = "jco",
  add = "reg.line"
  ) +
  facet_wrap(~Treatment) +
  stat_cor(label.y = 4.4) +
  stat_regline_equation(label.y = 100)

#floral species richness vs  BA

fig4B <- ggscatter(SEMvars,x="BA",y="floralrich",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
   stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=35, label.y=20, r.accuracy = 0.001)+
  stat_regline_equation(label.x=35, label.y=17)+
  ylab("Floral richness")+
  xlab("Basal area")+
  theme(legend.title = element_blank())

ggscatter(
  SEMvars, x = "BA", y = "floralrich",
  color = "Treatment", palette = "jco",
  add = "reg.line"
  ) +
  facet_wrap(~Treatment) +
  stat_cor(label.y = 4.4) +
  stat_regline_equation(label.y = 100)

```
Linear regressions to compare floral habitat (floral species richness) to bee assemblages measures

```{r}
#floral species richness vs bee abundance 
fig4C <- ggscatter(SEMvars,x="floralrich",y="beeab",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=125, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=110)+
  ylab("Bee abundance")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())


#floral species richness vs  Bee richness

fig4D<- ggscatter(SEMvars,x="floralrich",y="beerich",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=50, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=45)+
  ylab("Bee richness")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())

#floral species richness vs  Bee diversity

fig4E<- ggscatter(SEMvars,x="floralrich",y="Shannon",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
   stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=5, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=4.5)+
  ylab("Bee diversity (H')")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())

#final figure
figure4<- ggarrange(fig4A, fig4B, fig4C, fig4D, fig4E, 
                    labels = c("A","B","C", "D", "E"),
                    ncol = 2, nrow = 3, 
                    common.legend = TRUE, legend ="bottom")

```



## Supplemental material

Correlation analysis was performed on independent variables and highly correlated variables (≥ 0.60 correlation coefficient) were omitted from analysis 

```{r}

#rename normalize variables used for SEM
GLMvars_norm <- vars

#dataframe with independent variables
independentvars<- subset(GLMvars_norm, select = c("floralab",
                 "floralrich","Trees_ha","BA","QMD","Sky",
                 "Bare", "Forb", "Grass", "Litter", "Rock", 
                 "Shrub", "Tree", "Wood","Volume","MeanTemp","MaxTemp","MinTemp")) 

coriv <-cor(independentvars)

source("http://www.sthda.com/upload/rquery_cormat.r")
require("corrplot")
#Figure S12
rquery.cormat(independentvars)

write.csv(coriv, "cor.csv")

```

#Fourth corner analysis

The essential components of a fourth corner analysis are the R, Q, and L matrices

R: the site by environment matrix that describes the environmental conditions at each site

Q: the species by traits matrix that describes the traits of each species (can be both quantitative and categorical)

L: the site by species matrix that describes which species occur at each site (can be quantitative or presence/absence)

```{r}

##R (env)
env<- SEMvars
env=env[,c(1,2,3,4,6,7,8,13,21,23)]
env<- env %>% 
  column_to_rownames("Site")


##Q (traits)
#(row names= species/genus, each row is trait)
traits$Size<- as.factor(traits$Size)
traits$Nest1<- as.factor(traits$Nest1)
traits$Nest2<- as.factor(traits$Nest2)
traits$Sociality<- as.factor(traits$Sociality)
traits$Lecty<- as.factor(traits$Lecty)
traits$Season<- as.factor(traits$Season)

##L (abun)
#Import bee identification data 
#remove unidentified bee species
BeeID2<-subset(BeeID, GenusSpecies!="Unknown")
#Create abundance matrix by site 
abun <- BeeID2 %>% group_by(Site, Genus) %>% summarize(abundance = length(unique(Number)))
abun <- abun %>%
  spread(key = Genus, value = abundance)
abun<- abun %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
abun<- abun %>% 
  column_to_rownames("Site")
#change to integers
i <- c(1:30) # Specify columns you want to change
abun[ , i] <- apply(abun[ , i], 2,            # Specify own function within apply
                    function(x) as.integer(as.character(x)))
sapply(abun, class) 

#combine data frames into list 
bee_tglm <- list(abun, env, traits) 
names(bee_tglm) <- c("abun","env","traits")

```

Fourth corner analysis:

```{r}

fit=traitglm(bee_tglm$abun,bee_tglm$env,bee_tglm$traits)
fit$fourth #print fourth corner terms

plot(fit)

anova(fit, nBoot = 1000) 

##LASSO penalty

ft1=traitglm(bee_tglm$abun,bee_tglm$env,bee_tglm$traits,method="glm1path")
ft1$fourth #notice LASSO penalty has shrunk many interactions to zero

#plot
a        = max( abs(ft1$fourth.corner) )
colort   = colorRampPalette(c("blue","white","red")) 



plot.4th.2 = levelplot(t(as.matrix(fit$fourth.corner)), xlab="Environmental Variables",
 ylab="Species traits", col.regions=colort(100), at=seq(-a, a, length=100),
 scales = list( x= list(rot = 45)))
print(plot.4th.2)

#LASSO Penalty 

plot.4th = levelplot(t(as.matrix(ft1$fourth.corner)), xlab="Environmental Variables",
 ylab="Species traits", col.regions=colort(100), at=seq(-a, a, length=100),
 scales = list( x= list(rot = 45)))
print(plot.4th)

#Make it pretty
rownames(ft1$fourth.corner) <- c("Large", "Medium", "Small", "Above ground", "Below ground", "Both", "Kleptoparasitic", "Excavate", "Kleptoparasitic", "Rent", "Kleptoparasitic", "Multiple", "Social", "Solitary", "Kleptoparasitic", "Multiple", "Oligolectic", "Polylectic", "Early", "Late", "Mid-summer")
colnames(ft1$fourth.corner) <- c("Thinned stand", "Tree density", "Basal Area", "Canopy Openness", "Floral abundance", "Floral richness", "Bare ground", "Woody substrates", "Max Temperature")

S11A<- 
  levelplot(t(as.matrix(ft1$fourth.corner)), 
          xlab="Environmental Variables",
 ylab="Species traits",
 col.regions=colort(100), 
 at=seq(-a, a, length=100),
 scales = list(x= list(rot = 45), tck= 0))

```


### Fourth corner with Netting only

```{r}

##R (env)- same as above

##Q (traits)- remove columns of genera not captured in nets
traits2 <- traits %>% filter (!row_number () %in% c (16, 22))

##L (abun)- filter for net only
#data with only netting
BeesNet<- filter(BeeID2, Method == "Net")

#Create abundance matrix by site 
abun2 <- BeesNet %>% group_by(Site, Genus) %>% summarize(abundance = length(unique(Number)))
abun2 <- abun2 %>%
  spread(key = Genus, value = abundance)
#add missing rows to df
  #create missing rows
df2<- data.frame (c("C17", "C22", "C23","C24","C26","C30"))
names(df2) <- c("Site")  
  #Using rbind() function to insert above observation  
abun2 <- rbind(abun2, df2) 
abun2<- abun2 %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
abun2<- abun2 %>% 
  column_to_rownames("Site")
#change to integers
i <- c(1:28) # Specify columns you want to change
abun[ , i] <- apply(abun[ , i], 2,            # Specify own function within apply
                    function(x) as.integer(as.character(x)))
sapply(abun, class) 


#combine data frames into list 
bee_tglm2 <- list(abun2, env, traits2) 
names(bee_tglm2) <- c("abun2","env","traits2")

```

Fourth corner analysis (Net only)

```{r}

fit=traitglm(bee_tglm2$abun2,bee_tglm2$env,bee_tglm2$traits2)
fit$fourth #print fourth corner terms

plot(fit)

anova(fit, nBoot = 1000) 

##LASSO penalty

ft1=traitglm(bee_tglm2$abun2,bee_tglm2$env,bee_tglm2$traits2,method="glm1path")
ft1$fourth #notice LASSO penalty has shrunk many interactions to zero

#plot
a        = max( abs(ft1$fourth.corner) )
colort   = colorRampPalette(c("blue","white","red")) 



plot.4th.2 = levelplot(t(as.matrix(fit$fourth.corner)), xlab="Environmental Variables",
 ylab="Species traits", col.regions=colort(100), at=seq(-a, a, length=100),
 scales = list( x= list(rot = 45)))
print(plot.4th.2)

#LASSO Penalty 

plot.4th = levelplot(t(as.matrix(ft1$fourth.corner)), xlab="Environmental Variables",
 ylab="Species traits", col.regions=colort(100), at=seq(-a, a, length=100),
 scales = list( x= list(rot = 45)))
print(plot.4th)

#Make it pretty
rownames(ft1$fourth.corner) <- c("Large", "Medium", "Small", "Above ground", "Below ground", "Both", "Kleptoparasitic", "Excavate", "Kleptoparasitic", "Rent", "Kleptoparasitic", "Multiple", "Social", "Solitary", "Kleptoparasitic", "Multiple", "Oligolectic", "Polylectic", "Early", "Late", "Mid-summer")
colnames(ft1$fourth.corner) <- c("Thinned stand", "Tree density", "Basal Area", "Canopy Openness", "Floral abundance", "Floral richness", "Bare ground", "Woody substrates", "Max Temperature")

S11B<- 
  levelplot(t(as.matrix(ft1$fourth.corner)), 
          xlab="Environmental Variables",
 ylab="Species traits",
 col.regions=colort(100), 
 at=seq(-a, a, length=100),
 scales = list(x= list(rot = 45), tck= 0))

```
